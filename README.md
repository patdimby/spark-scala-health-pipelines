# ğŸ¥ Epidemic Big Data Pipeline â€“ Spark & Scala

## ğŸ“Œ Overview

This project implements a **large-scale Big Data pipeline for epidemiological surveillance**, built with **Apache Spark (Scala)** and based exclusively on **publicly accessible REST APIs**.

It is designed to demonstrate a **production-grade health data platform**, capable of ingesting, validating, transforming, and analyzing epidemic data at scale.

The pipeline follows modern **data engineering best practices** and is suitable for:

* National public health monitoring
* International health organizations (WHO, NGOs)
* Research & analytics platforms
* Senior / Lead Data Engineer portfolios

---

## ğŸ¯ Business Use Case

**Epidemic surveillance and monitoring**:

* Track confirmed cases, deaths, and trends per country and continent
* Produce reliable indicators for decision-makers
* Support early warning systems and analytical dashboards

Typical diseases covered by the data source include:

* COVID-19
* Dengue
* Cholera
* Influenza (depending on API availability)

---

## ğŸŒ Data Source (Public REST API)

This project relies on a **public, real-time REST API**:

* **disease.sh** â€“ Global epidemiological data
* Endpoint example:

  ```
  https://disease.sh/v3/covid-19/countries
  ```

âœ” No private database
âœ” No credentials required
âœ” Fully reproducible

---

## ğŸ—ï¸ Architecture

The pipeline follows a **Medallion Architecture**:

```
Public REST API
        â†“
Bronze Layer (Raw Ingestion)
        â†“
Silver Layer (Data Quality & Normalization)
        â†“
Gold Layer (Analytics & Indicators)
        â†“
Delta Lake Storage
```

### Layers description

* **Bronze**: Raw JSON ingestion from API (no transformation)
* **Silver**: Data quality checks, cleansing, normalization
* **Gold**: Aggregated epidemiological indicators ready for BI & ML

---

## âš™ï¸ Technology Stack

* **Language**: Scala 3.8.1
* **Processing**: Apache Spark 4.1.1
* **Storage**: Delta Lake
* **Ingestion**: REST API (HTTP)
* **Build Tool**: sbt
* **Data Architecture**: Bronze / Silver / Gold

---

## ğŸ§ª Data Quality Strategy

A dedicated **Data Quality layer** is implemented to ensure reliability of health data:

### Rules applied

* Mandatory fields must not be null
* Epidemiological metrics must be positive
* Invalid or corrupted records are automatically filtered

This approach aligns with **health data governance standards** and prevents analytical bias.

---

## ğŸ“Š Analytical Outputs (Gold Layer)

The Gold layer produces aggregated indicators such as:

* Total confirmed cases per continent
* Total deaths per continent
* Average number of new cases

These datasets are optimized for:

* BI tools (Power BI, Superset, Tableau)
* Epidemiological research
* Machine learning pipelines

---

## ğŸ“‚ Project Structure

```
epidemic-spark-pipeline/
 â”œâ”€â”€ config/          # Spark configuration
 â”œâ”€â”€ ingestion/       # REST API ingestion (Bronze)
 â”œâ”€â”€ quality/         # Data Quality rules (Silver)
 â”œâ”€â”€ transformation/ # Normalization logic (Silver)
 â”œâ”€â”€ analytics/       # Aggregations & indicators (Gold)
 â”œâ”€â”€ storage/         # Delta Lake persistence
 â””â”€â”€ pipeline/        # Orchestration entry point
```

---

## â–¶ï¸ How to Run

### Prerequisites

* Java 17.0.2
* Apache Spark 4.1.1
* sbt

### Run the pipeline

```bash
sbt run
```

The pipeline will:

1. Fetch data from the public API
2. Apply data quality checks
3. Generate analytical indicators
4. Persist results in Delta Lake format

---

## ğŸ” Security & Compliance Considerations

* No personal or identifiable health data (PHI)
* Public, aggregated epidemiological information only
* Architecture compatible with **RGPD / HIPAA-compliant extensions** if extended to private data

---

## ğŸš€ Possible Extensions

* Real-time streaming with Kafka & Spark Structured Streaming
* Machine Learning for epidemic trend prediction
* Alerting system for outbreak detection
* Cloud deployment (AWS / Azure / GCP)
* Integration with national health information systems

---

## ğŸ‘¤ Author

**RANOELISON Dimbisoa Adrianno**
Senior Data Engineer | Big Data | AI | Health Data

---

## ğŸ“„ License

This project is provided for **educational, research, and professional demonstration purposes**.

---

âœ… *This repository showcases a realistic, scalable, and production-oriented Big Data health pipeline.*
